{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONoFRAi+wm2wcmBBetSVL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neermalsha/poverty-of-Nepal-/blob/main/BM25_And_JM_Score_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary library for .docx file reading\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOiv3uV-hrRu",
        "outputId": "f8a8f66a-87bc-48ca-f9ab-777f6caf95d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Vxk6YQb7l_",
        "outputId": "aa082fd3-c620-4bfb-82a0-cc3c8b11ecf1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from docx import Document\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from math import log\n",
        "import re\n",
        "import math\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "q1h4FNs5iAjE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the text (same as before)\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
        "    return text.lower()"
      ],
      "metadata": {
        "id": "RG662uRGh7Ex"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load documents from a folder (handling .docx files)\n",
        "def get_documents_from_drive(folder_path):\n",
        "    documents = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".docx\"):  # For .docx files\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            doc = Document(file_path)\n",
        "            full_text = []\n",
        "            for para in doc.paragraphs:\n",
        "                full_text.append(para.text)\n",
        "            documents[filename] = preprocess(' '.join(full_text))\n",
        "    return documents\n",
        "\n",
        "# Set the folder path to your Google Drive documents folder\n",
        "folder_path = '/content/drive/MyDrive/Document/'  # Adjust this path to your actual folder\n",
        "documents = get_documents_from_drive(folder_path)\n"
      ],
      "metadata": {
        "id": "a3azHw-aiBYO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25 and Jelinek-Mercer functions (same as before)\n",
        "def compute_jm_scores(query, documents, term_frequency, doc_lengths, corpus_prob, lambda_param=0.1):\n",
        "    scores = {}\n",
        "    for doc_id, doc_text in documents.items():\n",
        "        score = 0\n",
        "        for term in query.split():\n",
        "            p_doc = term_frequency[doc_id].get(term, 0) / doc_lengths[doc_id]\n",
        "            p_corpus = corpus_prob.get(term, 0)\n",
        "\n",
        "            # Add a check to avoid log(0) or log(negative)\n",
        "            jm_value = (lambda_param * p_doc) + ((1 - lambda_param) * p_corpus)\n",
        "            if jm_value > 0:  # Only calculate log if value is positive\n",
        "                score += log(jm_value)\n",
        "            # else:  # You can handle the case where jm_value <= 0 differently if needed\n",
        "            #     score += 0  # For example, ignore the term and add 0 to the score\n",
        "        scores[doc_id] = score\n",
        "    return scores\n",
        "\n",
        "\n",
        "def compute_jm_scores(query, documents, term_frequency, doc_lengths, corpus_prob, lambda_param=0.1):\n",
        "    scores = {}\n",
        "    for doc_id, doc_text in documents.items():\n",
        "        score = 0\n",
        "        for term in query.split():\n",
        "            # Calculate term probabilities\n",
        "            p_doc = term_frequency[doc_id].get(term, 0) / doc_lengths[doc_id]\n",
        "            p_corpus = corpus_prob.get(term, 0)\n",
        "\n",
        "            # Check if the term is absent in both the document and corpus\n",
        "            if p_doc == 0 and p_corpus == 0:\n",
        "                continue  # Skip this term because log(0) is undefined\n",
        "\n",
        "            # Smooth probabilities to avoid math domain error\n",
        "            smoothed_prob = (lambda_param * p_doc) + ((1 - lambda_param) * p_corpus)\n",
        "\n",
        "            # Ensure the smoothed probability is greater than 0\n",
        "            if smoothed_prob > 0:\n",
        "                score += log(smoothed_prob)\n",
        "\n",
        "        scores[doc_id] = score\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "aAX0v1OQiQo4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build term frequencies, document frequencies, and corpus statistics\n",
        "term_frequency = defaultdict(lambda: defaultdict(int))\n",
        "document_frequency = defaultdict(int)\n",
        "doc_lengths = {}\n",
        "corpus_term_count = defaultdict(int)\n",
        "\n",
        "# Calculate term frequencies and document lengths\n",
        "for doc_id, doc_text in documents.items():\n",
        "    terms = doc_text.split()\n",
        "    if len(terms) == 0:  # Skip empty documents\n",
        "        continue\n",
        "    doc_lengths[doc_id] = len(terms)\n",
        "    for term in terms:\n",
        "        term_frequency[doc_id][term] += 1\n",
        "        corpus_term_count[term] += 1\n",
        "    for term in set(terms):\n",
        "        document_frequency[term] += 1\n",
        "\n",
        "# Calculate average document length\n",
        "avg_doc_length = np.mean(list(doc_lengths.values()))\n",
        "\n",
        "# Calculate corpus probability for Jelinek-Mercer\n",
        "total_terms_in_corpus = sum(corpus_term_count.values())\n",
        "corpus_prob = {term: count / total_terms_in_corpus for term, count in corpus_term_count.items()}\n"
      ],
      "metadata": {
        "id": "JKRNHqLYiU4Z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the file in Google Drive\n",
        "queries_file_path = '/content/drive/MyDrive/Document/Quries.txt'\n",
        "\n",
        "# Read the queries from the file\n",
        "with open(queries_file_path, 'r') as f:\n",
        "    queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Verify the loaded queries\n",
        "print(\"Loaded Queries:\", queries)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C3G5ndfm--w",
        "outputId": "e3f2f899-2ab4-4f37-df7d-3814e4633cd6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Queries: ['Digital marketing', 'Search engine optimization', 'Content marketing', 'Marketing', 'Video', 'Editing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for query in queries:\n",
        "    bm25_scores = compute_bm25_scores(query, documents, term_frequency, document_frequency, doc_lengths, avg_doc_length)\n",
        "    jm_scores = compute_jm_scores(query, documents, term_frequency, doc_lengths, corpus_prob)\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"BM25 Scores:\")\n",
        "    for doc_id, score in bm25_scores.items():\n",
        "        print(f\"{doc_id}: {score}\")\n",
        "\n",
        "    print(\"Jelinek-Mercer Scores:\")\n",
        "    for doc_id, score in jm_scores.items():\n",
        "        print(f\"{doc_id}: {score}\")\n",
        "\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvoL8heZmq4j",
        "outputId": "7a7b53e2-46e1-454f-a714-87ddcdc4dfd5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Digital marketing\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0.7000546958296271\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0.5656739385876729\n",
            "Doc 4.docx: 0.5572184238105776\n",
            "Doc 5.docx: 0.5864380579904716\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0.6351783661044088\n",
            "Doc 8.docx: 0.6424764706555894\n",
            "Doc 9.docx: 0.3902084356552091\n",
            "Doc 10.docx: 0\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: -3.5220888393508583\n",
            "Doc 2.docx: -3.7598311900862207\n",
            "Doc 3.docx: -3.623934700199401\n",
            "Doc 4.docx: -3.630102083411437\n",
            "Doc 5.docx: -3.6069741715001826\n",
            "Doc 6.docx: -3.7598311900862207\n",
            "Doc 7.docx: -3.5839688454147614\n",
            "Doc 8.docx: -3.5764379038778866\n",
            "Doc 9.docx: -3.6938930885942263\n",
            "Doc 10.docx: -3.7598311900862207\n",
            "\n",
            "\n",
            "Query: Search engine optimization\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 4.83747321907206\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 1.3839684131473797\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: -11.394329599056817\n",
            "Doc 2.docx: -10.16516595374328\n",
            "Doc 3.docx: -11.394329599056817\n",
            "Doc 4.docx: -11.394329599056817\n",
            "Doc 5.docx: -11.394329599056817\n",
            "Doc 6.docx: -11.394329599056817\n",
            "Doc 7.docx: -11.394329599056817\n",
            "Doc 8.docx: -11.394329599056817\n",
            "Doc 9.docx: -11.394329599056817\n",
            "Doc 10.docx: -11.116564963262384\n",
            "\n",
            "\n",
            "Query: Content marketing\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0.7000546958296271\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0.5656739385876729\n",
            "Doc 4.docx: 0.5572184238105776\n",
            "Doc 5.docx: 0.5864380579904716\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0.6351783661044088\n",
            "Doc 8.docx: 0.6424764706555894\n",
            "Doc 9.docx: 0.3902084356552091\n",
            "Doc 10.docx: 0\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: -3.5220888393508583\n",
            "Doc 2.docx: -3.7598311900862207\n",
            "Doc 3.docx: -3.623934700199401\n",
            "Doc 4.docx: -3.630102083411437\n",
            "Doc 5.docx: -3.6069741715001826\n",
            "Doc 6.docx: -3.7598311900862207\n",
            "Doc 7.docx: -3.5839688454147614\n",
            "Doc 8.docx: -3.5764379038778866\n",
            "Doc 9.docx: -3.6938930885942263\n",
            "Doc 10.docx: -3.7598311900862207\n",
            "\n",
            "\n",
            "Query: Marketing\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "\n",
            "\n",
            "Query: Video\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "\n",
            "\n",
            "Query: Editing\n",
            "BM25 Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "Jelinek-Mercer Scores:\n",
            "Doc 1.docx: 0\n",
            "Doc 2.docx: 0\n",
            "Doc 3.docx: 0\n",
            "Doc 4.docx: 0\n",
            "Doc 5.docx: 0\n",
            "Doc 6.docx: 0\n",
            "Doc 7.docx: 0\n",
            "Doc 8.docx: 0\n",
            "Doc 9.docx: 0\n",
            "Doc 10.docx: 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}